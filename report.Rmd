---
title: "PracticalML_project"
author: "Eric Zhang"
date: "July 23, 2017"
output: html_document
---

## Introduction
Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement - a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. 
In this project, we are going to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways.


## Data preparation and clean up
```{r}
library(data.table)
library(caret)
library(randomForest)
library(dplyr)
training <- read.table("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", sep = ',', header=T)
training <- tbl_df(training)
```


Cleaning dataset follows two criteria:
1. Missing data is not going to fit in the model. Therefore, any column with missing data will be excluded.
2. As indicated in the introduction part, only data from accelerometers on the belt, forearm, arm, and dumbell are used for machine learning.

In the practice, all columns with names implying they are statistics or not related to accelerometers are excluded.

```{r}
# we do not need columns with many missing data
fun <- function(x){sum(is.na(x))}
count <- sapply(training, fun)
complete <- training[, count<1]

# get accelarator related columns and use them plut 'classe' to get the train dataset
acc_ind <- grep("arm|dumbbell|forearm|belt", names(complete),value = T)
acc_train <- select(complete, acc_ind, classe)
acc_ind2 <- grep("kurtosis|skewness|amplitude|max|min", names(acc_train), value = T)
acc_train <- select(acc_train, -one_of(acc_ind2))
```

## Model building and cross validation

Firstly, a 5-fold cross validation has been conducted on the training set.

*(In order to increase the efficiency (yes, 19662 observations take some time to train), I also tried spitting the training set into training (75%) and validation (25%) only. No cross-validation is implemented. Training part will be used to do model building and validation for validation. randomForest is used because it is significantly faster than the method in caret)*

```{r, cache=TRUE}
cv_control <- trainControl(method='cv', 5)
rf_model <- train(classe ~ ., data=acc_train, method='rf',
                  troControl=cv_control, ntree=100)
rf_model
# in the comments, a training, validation split will be more efficient
#smp_size <- floor(0.75 * nrow(acc_train))
#set.seed(123)
#train_ind <- sample(seq_len(nrow(acc_train)), size = smp_size)
#training <- acc_train[train_ind, ]
#validation <- acc_train[-train_ind, ]
#rf_model <- randomForest(factor(classe)~ ., data=training)
#pred <- predict(rf_model, validation)
#confusionMatrix(pred, validation$classe)

```

As seen from the summary of the random forest model on the validation data, the model is very successful and resulted in an accuracy over 99.5%.

## Prediction on the test data set

```{r}
test <- read.table("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", sep = ',', header = TRUE)
test <- tbl_df(test)
# same feature elimination process as for the training set
count2 <- sapply(test, fun)
complete_test <- test[,count2<1]
acc_ind <- grep("arm|dumbbell|forearm|belt", names(complete_test), value=T)
acc_test <- select(complete_test, acc_ind)
# notice there is a "problem_id" column in the test data
```

## Appendix: Figures

```{r opts, echo=FALSE}
knitr::opts_chunk$set(fig.path = "figures/")
# plot the error rates of the model
plot(rf_model, log = 'y')

# plot the feature importance
varImp(rf_model)
```

